{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conuko/AI-Guild/blob/main/experiments/experiment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# U-Net Experiment 3: Training an U-Net on the entire dataset"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1PYQRhrsz19U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this notebook is to evaluate whether tile-overlapping has an effect on the resulting model.\n",
        "We will use the exact same setup as in experiment 1 except for the dataset. Each tile has a size of (256, 256) and the step size is 256 to exclude overlap."
      ],
      "metadata": {
        "collapsed": false,
        "id": "SxwBBw0_wKli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All previous experiments have only been used on a small part of the entire dataset. In this experiment all 16 images of\n",
        "the entire dataset will be split into tiles and used as input for our model."
      ],
      "metadata": {
        "collapsed": false,
        "id": "bT-w2qo6z19W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Helper Classes"
      ],
      "metadata": {
        "id": "rJznpxWwbvFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import pickle\n",
        "\n",
        "\n",
        "class EvaluationMetrics:\n",
        "    \"\"\"\n",
        "        This class calculates and summarizes evaluation metrics based on the predicted and true labels.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x_train, x_val, x_test, y_train, y_val, y_test, y_pred, dataset, training_dates, validation_dates, testing_dates, tile_size, step_size,\n",
        "                 run_count):\n",
        "       \n",
        "        self.y_pred = y_pred\n",
        "        if dataset == 'training':\n",
        "          self.y_true = y_train\n",
        "        elif dataset == 'validation':\n",
        "          self.y_true = y_val\n",
        "        elif dataset == 'testing':\n",
        "          self.y_true = y_test\n",
        "        else: \n",
        "          raise Exception(f'Specify the dataset to be used for calculating the metrics. The string has to be either \"testing\", \"training\" or \"validation\", however it was {dataset}.')\n",
        "        \n",
        "        self.class_statistics = self.get_statistics(x_train, x_val, x_test, y_train, y_val, y_test)\n",
        "\n",
        "        self.training_dates = training_dates\n",
        "        self.validation_dates = validation_dates\n",
        "        self.testing_dates = testing_dates\n",
        "        self.tile_size = tile_size\n",
        "        self.step_size = step_size\n",
        "        self.run_count = run_count\n",
        "\n",
        "        self.jacard = self.jacard_coef(self.y_true, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "        self.conf_matrix_land = self.confusion_matrix(self.y_true, y_pred, 2)\n",
        "        self.conf_matrix_valid = self.confusion_matrix(self.y_true, y_pred, 1)\n",
        "        self.conf_matrix_invalid = self.confusion_matrix(self.y_true, y_pred, 0)\n",
        "\n",
        "        self.precision_land = self.precision(self.conf_matrix_land)\n",
        "        self.sensitivity_recall_land = self.sensitivity_recall(self.conf_matrix_land)\n",
        "        self.specificy_land = self.specificy(self.conf_matrix_land)\n",
        "\n",
        "        self.precision_valid = self.precision(self.conf_matrix_valid)\n",
        "        self.sensitivity_recall_valid = self.sensitivity_recall(self.conf_matrix_valid)\n",
        "        self.specificy_valid = self.specificy(self.conf_matrix_valid)\n",
        "\n",
        "        self.precision_invalid = self.precision(self.conf_matrix_invalid)\n",
        "        self.sensitivity_recall_invalid = self.sensitivity_recall(self.conf_matrix_invalid)\n",
        "        self.specificy_invalid = self.specificy(self.conf_matrix_invalid)\n",
        "\n",
        "        self.f1_land = self.f1_scores(self.conf_matrix_land)\n",
        "        self.f1_invalid = self.f1_scores(self.conf_matrix_invalid)\n",
        "        self.f1_valid = self.f1_scores(self.conf_matrix_valid)\n",
        "\n",
        "    def jacard_coef(self, y_true, y_pred):\n",
        "        y_true_f = keras.backend.flatten(y_true)\n",
        "        y_pred_f = keras.backend.flatten(y_pred)\n",
        "\n",
        "        intersection = keras.backend.sum(y_true_f * y_pred_f)\n",
        "        return (intersection + 1.0) / (\n",
        "                keras.backend.sum(y_true_f) + keras.backend.sum(y_pred_f) - intersection + 1.0\n",
        "        )  #todo reason for +1?\n",
        "\n",
        "    def jacard_rounding_issue(self, y_true, y_pred):\n",
        "        # revert one hot encoding => binary tensor [0, 0, 1] back to label [2] (3D array to 2D array)\n",
        "        label_map_true = np.argmax(y_true, axis=-1)\n",
        "        label_map_pred = np.argmax(y_pred, axis=-1)\n",
        "        # convert 2D array into 1D array\n",
        "        flatten_true = np.reshape(label_map_true, (-1,))\n",
        "        flatten_pred = np.reshape(label_map_pred, (-1,))\n",
        "        # one hot encoding\n",
        "        one_hot_true = np.eye(3)[flatten_true]\n",
        "        one_hot_pred = np.eye(3)[flatten_pred]\n",
        "        # calculate intersection (A geschnitten B)\n",
        "        intersection = np.sum(one_hot_true * one_hot_pred)\n",
        "        # calculate union (a u B, A vereint B)\n",
        "        union = len(one_hot_true) + len(one_hot_pred) - intersection\n",
        "        # return jacard coefficient\n",
        "        return (intersection + 1) / (union + 1)\n",
        "\n",
        "    def confusion_matrix(self, y_true, y_pred, label):\n",
        "        true_positives = 0\n",
        "        false_positives = 0\n",
        "        true_negatives = 0\n",
        "        false_negatives = 0\n",
        "\n",
        "        # revert one hot encoding => binary tensor [0, 0, 1] back to label [2] (3D array to 2D array)\n",
        "        label_map_true = np.argmax(y_true, axis=-1)\n",
        "        label_map_pred = np.argmax(y_pred, axis=-1)\n",
        "        # convert 2D array into 1D array\n",
        "        flatten_true = np.reshape(label_map_true, (-1,))\n",
        "        flatten_pred = np.reshape(label_map_pred, (-1,))\n",
        "\n",
        "        tp_mask = (flatten_true == flatten_pred) & (flatten_true == label)\n",
        "        true_positives = np.count_nonzero(tp_mask)\n",
        "\n",
        "        fn_mask = (flatten_true == label) & (flatten_pred != label)\n",
        "        false_negatives = np.count_nonzero(fn_mask)\n",
        "\n",
        "        fp_mask = (flatten_true != label) & (flatten_pred == label)\n",
        "        false_positives = np.count_nonzero(fp_mask)\n",
        "\n",
        "        tn_mask = (flatten_true != label) & (flatten_pred != label)\n",
        "        true_negatives = np.count_nonzero(tn_mask)\n",
        "\n",
        "        return {\n",
        "            'true_positives': true_positives,\n",
        "            'false_positives': false_positives,\n",
        "            'true_negatives': true_negatives,\n",
        "            'false_negatives': false_negatives\n",
        "        }\n",
        "\n",
        "    def precision(self, conf_matrix):\n",
        "        return conf_matrix['true_positives'] / (conf_matrix['true_positives'] + conf_matrix['false_positives'])\n",
        "\n",
        "    def sensitivity_recall(self, conf_matrix):\n",
        "        return conf_matrix['true_positives'] / (conf_matrix['true_positives'] + conf_matrix['false_negatives'])\n",
        "\n",
        "    def negative_predictive(self, conf_matrix):\n",
        "        return conf_matrix['true_negatives'] / (conf_matrix['true_negatives'] + conf_matrix['false_negatives'])\n",
        "\n",
        "    def specificy(self, conf_matrix):\n",
        "        return conf_matrix['true_negatives'] / (conf_matrix['true_negatives'] + conf_matrix['false_positives'])\n",
        "\n",
        "    def f1_scores(self, conf_matrix):\n",
        "        prec = self.precision(conf_matrix)\n",
        "        recall = self.sensitivity_recall(conf_matrix)\n",
        "        return 2 * prec * recall / (prec + recall)\n",
        "\n",
        "    def print_metrics(self):\n",
        "        print(f'jacard index: {self.jacard} \\n')\n",
        "\n",
        "        print(f'precision_land: {self.precision_land}')\n",
        "        print(f'precision_valid: {self.precision_valid}')\n",
        "        print(f'precision_invalid: {self.precision_invalid} \\n')\n",
        "\n",
        "        print(f'recall_invalid_land: {self.sensitivity_recall_land}')\n",
        "        print(f'recall_invalid_land: {self.sensitivity_recall_valid}')\n",
        "        print(f'recall_invalid_land: {self.sensitivity_recall_invalid} \\n')\n",
        "\n",
        "        print(f'specificy_invalid_land: {self.specificy_land}')\n",
        "        print(f'specificy_invalid_valid: {self.specificy_valid}')\n",
        "        print(f'specificy_invalid_invalid: {self.specificy_invalid} \\n')\n",
        "\n",
        "        print(f'f1_land: {self.f1_land}')\n",
        "        print(f'f1_invalid: {self.f1_invalid}')\n",
        "        print(f'f1_valid: {self.f1_valid}')\n",
        "\n",
        "        print(f'Training dates: {self.training_dates}, validation dates: {self.validation_dates}, testing dates: {self.testing_dates}')\n",
        "        print(f'Number of run: {self.run_count}, tile_size: {self.tile_size}, step_size: {self.step_size}')\n",
        "\n",
        "    def save_to_file(self):\n",
        "        file_name = f'../metrics/{self.tile_size}_{self.step_size}_{self.run_count}.pkl'\n",
        "        with open(file_name, 'wb') as file:\n",
        "            pickle.dump(self, file)\n",
        "\n",
        "    def get_label_count(self, array):\n",
        "        revert_one_hot = np.argmax(array, (-1))\n",
        "        flatten = np.reshape(revert_one_hot, (-1))\n",
        "        unique_vals, counts = np.unique(flatten, return_counts=True)\n",
        "        label_count = {}\n",
        "        for val, count in zip(unique_vals, counts):\n",
        "            label_count[f'{val}'] = count\n",
        "        return label_count\n",
        "\n",
        "    def get_statistics(self, x_train, x_val, x_test, y_train, y_val, y_test):\n",
        "       return {'y_train': self.get_label_count(y_train),\n",
        "                 'y_val': self.get_label_count(y_val), 'y_test': self.get_label_count(y_test)}\n",
        "    # todo add pixel accuracy"
      ],
      "metadata": {
        "id": "r6um1iVpbpix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Loading + Preparing Data"
      ],
      "metadata": {
        "id": "TQiNFtcib6wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osm1lHOLb-Is",
        "outputId": "0234ec24-18d7-4e80-dd08-0cdeaf9a20af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls\n",
        "%cd drive/MyDrive/MachineLearning/Geospatial_ML\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV1KZvqMb_6S",
        "outputId": "a21c21e6-eb3f-4696-f451-476768edf36d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n",
            "/content/drive/.shortcut-targets-by-id/15HUD3sGdfvxy5Y_bjvuXgrzwxt7TzRfm/MachineLearning/Geospatial_ML\n",
            "architecture.drawio  evaluation  notebooks     README.md\n",
            "Copy_of_unet.ipynb   models\t prepare_data  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    concatenate,\n",
        "    Conv2DTranspose,\n",
        "    Dropout,\n",
        "    UpSampling2D\n",
        ")\n",
        "from keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle"
      ],
      "metadata": {
        "id": "0FB7ZXQkcKB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = \"../data_colab/256_256\"\n",
        "\n",
        "x_input = []\n",
        "y_mask = []\n",
        "\n",
        "count = 0\n",
        "\n",
        "for file_name in os.listdir(data_directory):\n",
        "  file_path = f'{data_directory}/{file_name}'\n",
        "  print(f'Loading array {file_path}')\n",
        "  numpy_array = np.load(file_path) \n",
        "  y_temp  = numpy_array['y_mask']\n",
        "  x_temp  = numpy_array['x_input']\n",
        "\n",
        "  if count == 0:\n",
        "    x_input = x_temp\n",
        "    y_mask = y_temp\n",
        "  else:\n",
        "    x_input = np.concatenate((x_input, x_temp), axis=0)\n",
        "    y_mask = np.concatenate((y_mask, y_temp), axis=0)\n",
        "  count += 1\n",
        "print(f'Amount of images used: {count}')\n",
        "print(x_input.shape)\n",
        "print(y_mask.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_9zuXlOA1BWO",
        "outputId": "22bc3eeb-6b3e-4e07-d513-0361029c06e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading array ../data_colab/256_256/2022_10_13.npz\n",
            "Loading array ../data_colab/256_256/2022_07_15.npz\n",
            "Loading array ../data_colab/256_256/2022_09_18.npz\n",
            "Loading array ../data_colab/256_256/2022_06_20.npz\n",
            "Loading array ../data_colab/256_256/2022_10_23.npz\n",
            "Loading array ../data_colab/256_256/2022_07_25.npz\n",
            "Loading array ../data_colab/256_256/2022_08_04.npz\n",
            "Loading array ../data_colab/256_256/2022_07_10.npz\n",
            "Loading array ../data_colab/256_256/2022_07_30.npz\n",
            "Loading array ../data_colab/256_256/2022_08_14.npz\n",
            "Loading array ../data_colab/256_256/2022_08_24.npz\n",
            "Loading array ../data_colab/256_256/2022_09_03.npz\n",
            "Loading array ../data_colab/256_256/2022_12_12.npz\n",
            "Loading array ../data_colab/256_256/2022_09_08.npz\n",
            "Loading array ../data_colab/256_256/2022_12_02.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use data generators: Instead of loading all your data into memory at once, use data generators to load the data in batches during training. This can help reduce memory usage. data generators can also split on the fly"
      ],
      "metadata": {
        "id": "_6o1YGBMAbgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "# save the entire dataset in one .npz file\n",
        "\n",
        "\n",
        "class CustomDataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, data_path, batch_size, validation_split=0.2, test_split=0.1, shuffle=True):\n",
        "        self.data_path = data_path\n",
        "        self.batch_size = batch_size\n",
        "        self.validation_split = validation_split\n",
        "        self.test_split = test_split\n",
        "        self.shuffle = shuffle\n",
        "        \n",
        "        # Load the input and target data from the .npz file\n",
        "        self.data = np.load(self.data_path)\n",
        "        self.x = self.data['x_input']\n",
        "        self.y = self.data['y_mask']\n",
        "        self.num_samples = self.x.shape[0]\n",
        "        \n",
        "        # Split the data into training, validation, and test sets\n",
        "        self.num_train = int(self.num_samples * (1 - validation_split - test_split))\n",
        "        self.num_val = int(self.num_samples * validation_split)\n",
        "        self.num_test = self.num_samples - self.num_train - self.num_val\n",
        "        \n",
        "        # initializes an array of indices representing the samples in the dataset\n",
        "        self.indices = np.arange(self.num_samples)\n",
        "        if shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.num_samples / float(self.batch_size)))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        \n",
        "        # Load the input and target data for the batch from the arrays\n",
        "        batch_x = self.x[batch_indices]\n",
        "        batch_y = self.y[batch_indices]\n",
        "        \n",
        "        return batch_x, batch_y\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "    \n",
        "    def get_validation_data(self):\n",
        "        val_indices = self.indices[:self.num_val]\n",
        "        \n",
        "        # Load the validation input and target data from the arrays\n",
        "        val_x = self.x[val_indices]\n",
        "        val_y = self.y[val_indices]\n",
        "        \n",
        "        return val_x, val_y\n",
        "    \n",
        "    def get_test_data(self):\n",
        "        test_indices = self.indices[self.num_train + self.num_val:]\n",
        "        \n",
        "        # Load the test input and target data from the arrays\n",
        "        test_x = self.x[test_indices]\n",
        "        test_y = self.y[test_indices]\n",
        "        \n",
        "        return test_x, test_y\n"
      ],
      "metadata": {
        "id": "_2iptIermioZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizing(X, y):\n",
        "\n",
        "  print(y.shape)\n",
        "  y_one_hot =  np.array([tf.one_hot(item, depth=3).numpy() for item in y])\n",
        "  print(y_one_hot.shape)\n",
        "  X_normal = X/255\n",
        "  return X_normal, y_one_hot"
      ],
      "metadata": {
        "id": "crUpzYlEcgq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_input, y_mask = normalizing(x_input, y_mask)"
      ],
      "metadata": {
        "id": "c4Q8g6SOcla5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Display Images"
      ],
      "metadata": {
        "id": "6a5sQEyg8qif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    if len(display_list[i].shape) == 3:\n",
        "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
        "        #plt.axis('off')\n",
        "    else:\n",
        "        plt.imshow(display_list[i])\n",
        "  plt.show()\n",
        "\n",
        "def display(list_train, list_mask):\n",
        "  for idx, img_train in enumerate(list_train):\n",
        "    sample_image, sample_mask = list_train[idx], list_mask[idx]\n",
        "    sample_image = sample_image[..., :4]\n",
        "    display_image([sample_image, sample_mask])"
      ],
      "metadata": {
        "id": "KI1vJAvf8vLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(x_input[:6], y_mask[:6])"
      ],
      "metadata": {
        "id": "vsRuRTmX8z3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Compiling the model"
      ],
      "metadata": {
        "id": "L87xH5zJcYO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_2d(input_shape, num_classes):\n",
        "\n",
        "    # Define the input layer\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Downsample layers\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    # Upsample layers\n",
        "    up5 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv3], axis=-1)\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(up5)\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv2], axis=-1)\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv1], axis=-1)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    # Output layer\n",
        "    output = Conv2D(num_classes, (1, 1), activation='softmax')(conv7)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs=[inputs], outputs=[output])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "cUPkEV0Ic2nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = unet_2d(input_shape=(256, 256, 5), num_classes=3)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7j2vHOtc4my",
        "outputId": "ddc1f63b-ce55-4e5f-c77c-136e2ca95297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 5  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  2944        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_2[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 64, 64, 512)  0           ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64, 64, 768)  0           ['up_sampling2d[0][0]',          \n",
            "                                                                  'conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 64, 64, 256)  1769728     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_9[0][0]']               \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 128, 38  0           ['up_sampling2d_1[0][0]',        \n",
            "                                4)                                'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 128, 128, 12  442496      ['concatenate_1[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_10[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_11[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256, 256, 19  0           ['up_sampling2d_2[0][0]',        \n",
            "                                2)                                'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 256, 256, 64  110656      ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_12[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 256, 256, 3)  195         ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,784,195\n",
            "Trainable params: 7,784,195\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Splitting dataset"
      ],
      "metadata": {
        "id": "z7eN8KMd9FOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets, with 80% for training and 20% for testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_input, y_mask, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the training data into training and validation sets, with 75% for training and 25% for validation\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting datasets\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Training labels shape:\", y_train.shape)\n",
        "print(\"Validation data shape:\", x_val.shape)\n",
        "print(\"Validation labels shape:\", y_val.shape)\n",
        "print(\"Test data shape:\", x_test.shape)\n",
        "print(\"Test labels shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "9RYOFIGC_VWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Model training"
      ],
      "metadata": {
        "id": "R55UTUmGc73x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tile_size = 256\n",
        "step_size = 256\n",
        "saving_path = 'experiment_3'\n",
        "training_dates = '17 images skikitsplit'\n",
        "validation_dates = '17 images skikitsplit'\n",
        "testing_dates = '17 images skikitsplit'"
      ],
      "metadata": {
        "id": "qHDLwE-AftkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_training(count):\n",
        "  print(f'Start training number {count}')\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=categorical_crossentropy,\n",
        "                metrics=['accuracy']) # ??? alternatives\n",
        "\n",
        "  early_stop = EarlyStopping(monitor='accuracy', patience=5) \n",
        "\n",
        "  model_history = model.fit(x=x_train, y=y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stop])\n",
        "\n",
        "  # saving model\n",
        "  model_name = f'{tile_size}_{step_size}_run_{count}'\n",
        "  model.save(f'../models/{saving_path}/model_{model_name}.h5')\n",
        "\n",
        "  # saving model history\n",
        "  with open(f'../models/{saving_path}/history_{model_name}.pkl', 'wb') as file_pi:\n",
        "      pickle.dump(model_history.history, file_pi)\n",
        "\n",
        "  # making predictions\n",
        "  predictions = model.predict(x_test)\n",
        "\n",
        "  # calculating metrics\n",
        "  metrics = EvaluationMetrics(x_train, x_val, x_test, y_train, y_val, y_test, predictions, training_dates, validation_dates, testing_dates, tile_size, step_size, count)\n",
        "  print(f'jacard index: {metrics.jacard}')\n",
        "  # saving metrics\n",
        "  with open(f'../metrics/{saving_path}/history_{model_name}.pkl', 'wb') as file_pi:\n",
        "      pickle.dump(metrics, file_pi)\n",
        "\n",
        "  return metrics, model_history"
      ],
      "metadata": {
        "id": "lYGEuLXWdKLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics, model_history = execute_training(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD4NX8eCffFZ",
        "outputId": "db8ffd83-c01c-4509-d584-27b8e0a54117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training number 0\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 31s 538ms/step - loss: 0.6058 - accuracy: 0.7843 - val_loss: 27.4159 - val_accuracy: 0.8723\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.1863 - accuracy: 0.9432 - val_loss: 18.5538 - val_accuracy: 0.9680\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.1154 - accuracy: 0.9677 - val_loss: 19.3050 - val_accuracy: 0.9706\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0930 - accuracy: 0.9715 - val_loss: 11.2852 - val_accuracy: 0.9732\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0847 - accuracy: 0.9715 - val_loss: 10.6627 - val_accuracy: 0.9740\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0728 - accuracy: 0.9736 - val_loss: 10.6931 - val_accuracy: 0.9723\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0777 - accuracy: 0.9718 - val_loss: 11.3525 - val_accuracy: 0.9727\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 6s 262ms/step - loss: 0.0684 - accuracy: 0.9748 - val_loss: 8.5712 - val_accuracy: 0.9760\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0626 - accuracy: 0.9768 - val_loss: 9.7437 - val_accuracy: 0.9770\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0585 - accuracy: 0.9783 - val_loss: 9.0649 - val_accuracy: 0.9778\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0591 - accuracy: 0.9779 - val_loss: 6.0201 - val_accuracy: 0.9804\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0583 - accuracy: 0.9781 - val_loss: 4.9916 - val_accuracy: 0.9813\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0539 - accuracy: 0.9799 - val_loss: 5.9997 - val_accuracy: 0.9806\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0555 - accuracy: 0.9793 - val_loss: 8.0892 - val_accuracy: 0.9804\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0529 - accuracy: 0.9801 - val_loss: 3.9424 - val_accuracy: 0.9822\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0500 - accuracy: 0.9812 - val_loss: 6.9062 - val_accuracy: 0.9818\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 6s 262ms/step - loss: 0.0485 - accuracy: 0.9819 - val_loss: 4.9770 - val_accuracy: 0.9816\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0469 - accuracy: 0.9825 - val_loss: 5.4963 - val_accuracy: 0.9827\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0452 - accuracy: 0.9832 - val_loss: 6.3123 - val_accuracy: 0.9824\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0423 - accuracy: 0.9840 - val_loss: 3.8550 - val_accuracy: 0.9835\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0427 - accuracy: 0.9839 - val_loss: 5.1050 - val_accuracy: 0.9828\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0425 - accuracy: 0.9843 - val_loss: 4.5150 - val_accuracy: 0.9817\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0407 - accuracy: 0.9848 - val_loss: 3.1836 - val_accuracy: 0.9852\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0400 - accuracy: 0.9847 - val_loss: 5.3702 - val_accuracy: 0.9837\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0406 - accuracy: 0.9846 - val_loss: 3.8332 - val_accuracy: 0.9841\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0356 - accuracy: 0.9868 - val_loss: 5.8065 - val_accuracy: 0.9840\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0405 - accuracy: 0.9848 - val_loss: 5.1446 - val_accuracy: 0.9839\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0353 - accuracy: 0.9866 - val_loss: 3.5648 - val_accuracy: 0.9856\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0336 - accuracy: 0.9873 - val_loss: 2.7021 - val_accuracy: 0.9858\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0329 - accuracy: 0.9876 - val_loss: 4.3483 - val_accuracy: 0.9850\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0352 - accuracy: 0.9872 - val_loss: 3.8617 - val_accuracy: 0.9843\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0336 - accuracy: 0.9874 - val_loss: 3.7315 - val_accuracy: 0.9850\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0295 - accuracy: 0.9891 - val_loss: 4.5653 - val_accuracy: 0.9873\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0306 - accuracy: 0.9882 - val_loss: 6.2937 - val_accuracy: 0.9834\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0366 - accuracy: 0.9866 - val_loss: 3.4259 - val_accuracy: 0.9818\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0284 - accuracy: 0.9895 - val_loss: 3.8589 - val_accuracy: 0.9853\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0250 - accuracy: 0.9906 - val_loss: 4.8525 - val_accuracy: 0.9831\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0238 - accuracy: 0.9910 - val_loss: 4.8428 - val_accuracy: 0.9845\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0232 - accuracy: 0.9908 - val_loss: 3.7181 - val_accuracy: 0.9841\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0234 - accuracy: 0.9909 - val_loss: 12.4108 - val_accuracy: 0.9581\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0227 - accuracy: 0.9910 - val_loss: 5.0327 - val_accuracy: 0.9848\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0170 - accuracy: 0.9935 - val_loss: 5.4298 - val_accuracy: 0.9857\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 7.2757 - val_accuracy: 0.9831\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 12.5005 - val_accuracy: 0.9760\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 11.9873 - val_accuracy: 0.9803\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 13.5153 - val_accuracy: 0.9762\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 6.7261 - val_accuracy: 0.9839\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 9.3823 - val_accuracy: 0.9837\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0096 - accuracy: 0.9965 - val_loss: 11.0559 - val_accuracy: 0.9804\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 15.4347 - val_accuracy: 0.9784\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 13.0329 - val_accuracy: 0.9821\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 17.0326 - val_accuracy: 0.9788\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 16.1836 - val_accuracy: 0.9774\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 15.6613 - val_accuracy: 0.9817\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 18.7993 - val_accuracy: 0.9791\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 20.2227 - val_accuracy: 0.9798\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 17.0023 - val_accuracy: 0.9812\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 17.4114 - val_accuracy: 0.9818\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 23.0527 - val_accuracy: 0.9801\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 25.4446 - val_accuracy: 0.9810\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 22.3578 - val_accuracy: 0.9809\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 29.4420 - val_accuracy: 0.9779\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 28.1768 - val_accuracy: 0.9789\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 26.0997 - val_accuracy: 0.9804\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 19.6109 - val_accuracy: 0.9810\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 23.5741 - val_accuracy: 0.9792\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 28.9849 - val_accuracy: 0.9786\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 24.8185 - val_accuracy: 0.9807\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 32.9773 - val_accuracy: 0.9787\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 31.5041 - val_accuracy: 0.9780\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 34.6557 - val_accuracy: 0.9770\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 29.8863 - val_accuracy: 0.9794\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 37.8200 - val_accuracy: 0.9743\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 36.6551 - val_accuracy: 0.9775\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 44.6337 - val_accuracy: 0.9744\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 40.6062 - val_accuracy: 0.9770\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 44.6695 - val_accuracy: 0.9758\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 36.3669 - val_accuracy: 0.9774\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 38.2094 - val_accuracy: 0.9775\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 37.2741 - val_accuracy: 0.9771\n",
            "24/24 [==============================] - 2s 63ms/step\n",
            "jacard index: 0.9814321398735046\n",
            "Start training number 1\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 13s 353ms/step - loss: 0.0747 - accuracy: 0.9851 - val_loss: 7.4269 - val_accuracy: 0.9698\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0213 - accuracy: 0.9924 - val_loss: 9.4885 - val_accuracy: 0.9797\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 6s 262ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 17.4340 - val_accuracy: 0.9740\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 17.0381 - val_accuracy: 0.9741\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 19.5665 - val_accuracy: 0.9742\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 18.3841 - val_accuracy: 0.9792\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 22.9273 - val_accuracy: 0.9785\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 26.2436 - val_accuracy: 0.9779\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 27.3142 - val_accuracy: 0.9793\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 29.2800 - val_accuracy: 0.9790\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 30.8144 - val_accuracy: 0.9791\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 32.2888 - val_accuracy: 0.9789\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 32.6462 - val_accuracy: 0.9801\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 33.3293 - val_accuracy: 0.9789\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 35.6829 - val_accuracy: 0.9785\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 30.5352 - val_accuracy: 0.9800\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 32.0419 - val_accuracy: 0.9805\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 32.2154 - val_accuracy: 0.9800\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 33.3781 - val_accuracy: 0.9806\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 36.1876 - val_accuracy: 0.9798\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 35.4158 - val_accuracy: 0.9799\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 32.4918 - val_accuracy: 0.9807\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 6s 262ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 35.8148 - val_accuracy: 0.9798\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 32.5729 - val_accuracy: 0.9808\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 9.5464e-04 - accuracy: 0.9997 - val_loss: 33.9498 - val_accuracy: 0.9805\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 9.2901e-04 - accuracy: 0.9997 - val_loss: 33.3319 - val_accuracy: 0.9808\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 9.4715e-04 - accuracy: 0.9997 - val_loss: 31.0520 - val_accuracy: 0.9814\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 33.4004 - val_accuracy: 0.9804\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 33.2282 - val_accuracy: 0.9810\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 9.9883e-04 - accuracy: 0.9997 - val_loss: 32.3705 - val_accuracy: 0.9811\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 8.9335e-04 - accuracy: 0.9997 - val_loss: 35.5862 - val_accuracy: 0.9806\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 8.1960e-04 - accuracy: 0.9997 - val_loss: 33.4226 - val_accuracy: 0.9813\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 8.1962e-04 - accuracy: 0.9997 - val_loss: 34.9075 - val_accuracy: 0.9804\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 7.6915e-04 - accuracy: 0.9997 - val_loss: 34.5833 - val_accuracy: 0.9815\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 7.6871e-04 - accuracy: 0.9997 - val_loss: 38.1366 - val_accuracy: 0.9802\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 7.5842e-04 - accuracy: 0.9997 - val_loss: 34.0358 - val_accuracy: 0.9811\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 7.3275e-04 - accuracy: 0.9998 - val_loss: 34.9824 - val_accuracy: 0.9809\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 6.6868e-04 - accuracy: 0.9998 - val_loss: 35.3224 - val_accuracy: 0.9816\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 5.9492e-04 - accuracy: 0.9998 - val_loss: 36.5159 - val_accuracy: 0.9813\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 5.6494e-04 - accuracy: 0.9998 - val_loss: 39.1183 - val_accuracy: 0.9816\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 5.2917e-04 - accuracy: 0.9998 - val_loss: 39.3262 - val_accuracy: 0.9816\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 5.3433e-04 - accuracy: 0.9998 - val_loss: 39.1119 - val_accuracy: 0.9810\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 6.0550e-04 - accuracy: 0.9998 - val_loss: 38.7763 - val_accuracy: 0.9792\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 7.3352e-04 - accuracy: 0.9998 - val_loss: 28.2652 - val_accuracy: 0.9828\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 8.9291e-04 - accuracy: 0.9997 - val_loss: 36.1250 - val_accuracy: 0.9780\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 8.5172e-04 - accuracy: 0.9997 - val_loss: 30.9862 - val_accuracy: 0.9824\n",
            "24/24 [==============================] - 2s 64ms/step\n",
            "jacard index: 0.9825244545936584\n",
            "Start training number 2\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 13s 355ms/step - loss: 0.0470 - accuracy: 0.9889 - val_loss: 5.5538 - val_accuracy: 0.9843\n",
            "Epoch 2/100\n",
            "12/24 [==============>...............] - ETA: 2s - loss: 0.0144 - accuracy: 0.9951"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "statistics labels"
      ],
      "metadata": {
        "id": "gZZKaGTb-wsO"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}